\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lecun-89c}
\citation{goodfellow}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Definition}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Project Overview}{1}{subsection.1.1}}
\citation{goodfellow}
\citation{sermanet-icpr-12}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Problem Statement}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}Metrics}{2}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Analysis}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Data Exploration}{3}{subsection.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces This table shows the frequency of various lengths of digits that are found in the Training dataset.}}{3}{table.2}}
\newlabel{table:lengths}{{2}{3}{This table shows the frequency of various lengths of digits that are found in the Training dataset}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Exploratory Visualization}{3}{subsection.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces This table details information about the datasets. These datasets include A.) The training set that was split to create the D.) Train dataset and E.) Valid dataset, B.) The extra dataset that is used to create the training and validation datasets, C.) The test set that is used to evaluate the model, D.) The training set that is used for training the model (created from the train and extra datasets), and E.) The validation set that is used to tune hyper-parameters of the model. Size is the number of images in each dataset. Max height is the height of the tallest image in each dataset. Max width is the width of the widest image in each dataset. Mean is the mean pixel value of the images in the dataset. Std. Dev. is the standard deviation of the pixel values in the images. \textit  {Note:} The final Training dataset and Validation sets have little information about them because they are created after the images from the Train and Extra datasets are processed and therefore have been normalized so they have no meaningful mean or standard deviation.}}{4}{table.1}}
\newlabel{table:stats}{{1}{4}{This table details information about the datasets. These datasets include A.) The training set that was split to create the D.) Train dataset and E.) Valid dataset, B.) The extra dataset that is used to create the training and validation datasets, C.) The test set that is used to evaluate the model, D.) The training set that is used for training the model (created from the train and extra datasets), and E.) The validation set that is used to tune hyper-parameters of the model. Size is the number of images in each dataset. Max height is the height of the tallest image in each dataset. Max width is the width of the widest image in each dataset. Mean is the mean pixel value of the images in the dataset. Std. Dev. is the standard deviation of the pixel values in the images. \textit {Note:} The final Training dataset and Validation sets have little information about them because they are created after the images from the Train and Extra datasets are processed and therefore have been normalized so they have no meaningful mean or standard deviation}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example image from the Training dataset. Bounding boxes for each digit has been added to the image.}}{4}{figure.1}}
\newlabel{fig:Original Figure}{{1}{4}{An example image from the Training dataset. Bounding boxes for each digit has been added to the image}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The only example in the training dataset that has six digits.}}{4}{figure.2}}
\newlabel{fig:6 Digit Figure}{{2}{4}{The only example in the training dataset that has six digits}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Algorithms and Techniques}{4}{subsection.2.3}}
\citation{alex}
\citation{alex}
\citation{goodfellow}
\citation{goodfellow}
\citation{alex}
\citation{goodfellow}
\citation{goodfellow}
\citation{goodfellow}
\citation{goodfellow}
\citation{goodfellow}
\citation{goodfellow}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\hskip -1em.\nobreakspace  {}Benchmark}{6}{subsection.2.4}}
\citation{goodfellow}
\citation{goodfellow}
\citation{sermanet-icpr-12}
\citation{sermanet-icpr-12}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Methodology}{7}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Data Processing}{7}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Implementation}{7}{subsection.3.2}}
\citation{Google}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The same image from Figure 1 after it has been processed (cropped, resized to 50 x 50 pixels and converted to grayscale). }}{8}{figure.3}}
\newlabel{fig:Processed Figure}{{3}{8}{The same image from Figure 1 after it has been processed (cropped, resized to 50 x 50 pixels and converted to grayscale)}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A picture of the tensorflow graph. The model is the network itself and the rest of it is the what allows for training and saving the graph.}}{8}{figure.4}}
\newlabel{fig:model image}{{4}{8}{A picture of the tensorflow graph. The model is the network itself and the rest of it is the what allows for training and saving the graph}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Picture of the network from tensorboard. Larger image avaiable at \url  {http://imgur.com/cx9DINa}}}{9}{figure.5}}
\newlabel{fig:network figure}{{5}{9}{Picture of the network from tensorboard. Larger image avaiable at \url {http://imgur.com/cx9DINa}}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Refinement}{9}{subsection.3.3}}
\citation{goodfellow}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces This graph of the loss function over training steps shows how the loss decreased as the model was trained.}}{10}{figure.6}}
\newlabel{fig:loss}{{6}{10}{This graph of the loss function over training steps shows how the loss decreased as the model was trained}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Results}{10}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Model Evaluation and Validation}{10}{subsection.4.1}}
\citation{goodfellow}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A graph showing how the accuracy on the training batch and the accuracy on the validation set changed as the model was trained.}}{11}{figure.7}}
\newlabel{fig:accuracy}{{7}{11}{A graph showing how the accuracy on the training batch and the accuracy on the validation set changed as the model was trained}{figure.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Accuracy of the model on each dataset where the Train dataset is the last accuracy on the last batch of training data.}}{11}{table.3}}
\newlabel{table:acc}{{3}{11}{Accuracy of the model on each dataset where the Train dataset is the last accuracy on the last batch of training data}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces An example of some of the output of the model. The images are images that were fed into the model. The Label is the label for that image from the dataset and the Predict is the value of the output when that image is feed into the network.}}{11}{figure.8}}
\newlabel{fig:output}{{8}{11}{An example of some of the output of the model. The images are images that were fed into the model. The Label is the label for that image from the dataset and the Predict is the value of the output when that image is feed into the network}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Justification}{11}{subsection.4.2}}
\citation{xavier}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The image on the left is one of the images that has been processed and is ready to be fed into the network. The image on the right is the image after it has been through a single convolution.}}{12}{figure.9}}
\newlabel{fig:two image}{{9}{12}{The image on the left is one of the images that has been processed and is ready to be fed into the network. The image on the right is the image after it has been through a single convolution}{figure.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Conclusion}{12}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Free Form Visualization}{12}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces This shows the activation of the third convolutional layer weights in the network. The top and bottom light blue lines show that the training doesn't begin to effect this set of weights until almost 40,000 training steps.}}{12}{figure.10}}
\newlabel{fig:conv}{{10}{12}{This shows the activation of the third convolutional layer weights in the network. The top and bottom light blue lines show that the training doesn't begin to effect this set of weights until almost 40,000 training steps}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces This shows the activation of the hidden layer weights in the fifth logits in the network. The top and bottom light blue lines show that the training doesn't begin to effect this set of weights until almost 30,000 training steps.}}{12}{figure.11}}
\newlabel{fig:hidden}{{11}{12}{This shows the activation of the hidden layer weights in the fifth logits in the network. The top and bottom light blue lines show that the training doesn't begin to effect this set of weights until almost 30,000 training steps}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces This shows the activation of the output layer weights in the first logits in the network. The top and bottom light blue lines show that the training starts to change weights almost immediately.}}{12}{figure.12}}
\newlabel{fig:logits}{{12}{12}{This shows the activation of the output layer weights in the first logits in the network. The top and bottom light blue lines show that the training starts to change weights almost immediately}{figure.12}{}}
\citation{goodfellow}
\citation{sermanet-icpr-12}
\citation{goodfellow}
\citation{goodfellow}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Reflection}{13}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Improvement}{13}{subsection.5.3}}
\citation{goodfellow}
\bibstyle{ieee}
\bibdata{bib}
\bibcite{Google}{1}
\bibcite{xavier}{2}
\bibcite{goodfellow}{3}
\bibcite{alex}{4}
\bibcite{lecun-89c}{5}
\bibcite{sermanet-icpr-12}{6}
